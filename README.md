# PandasWorkFlow
PyPandas and NumPy Handson


# Added PySpark Library for my local Anaconda Distribution. 
Steps to follow

1. Dowload Apache Spark from the official WebSite.
1. Downlod Hadoop winutils.exe
1. Extract Spark Files and copy the winutils.exe to the spark BIN directory.

Set the following environment variables

Name						Value
SPARK_HOME					D:\spark\spark-2.2.1-bin-hadoop2.7
HADOOP_HOME					D:\spark\spark-2.2.1-bin-hadoop2.7
PYSPARK_DRIVER_PYTHON		jupyter
PYSPARK_DRIVER_PYTHON_OPTS	notebook


You are all set use PySpark !!! 

